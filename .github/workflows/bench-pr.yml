name: PR Benchmarks

on:
  pull_request:
    types: [ labeled, synchronize ]
    branches: [ "develop" ]
  workflow_dispatch: { }

permissions:
  actions: write
  contents: read
  pull-requests: write
  id-token: write

jobs:
  label_trigger:
    runs-on: ubuntu-latest
    if: ${{ contains(github.event.head_commit.message, '[benchmark]') || github.event.label.name == 'benchmark' && github.event_name == 'pull_request' }}
    steps:
      # We remove the benchmark label first so that the workflow can be re-triggered.
      - uses: actions-ecosystem/action-remove-labels@v1
        with:
          labels: benchmark

  bench:
    needs: label_trigger
    runs-on:
      - runs-on=${{ github.run_id }}
      - family=c6id.8xlarge
      - image=ubuntu24-full-x64
      - spot=false
      - tag=${{ matrix.benchmark.id }}
    strategy:
      matrix:
        benchmark:
          - id: random_access
            name: Random Access
          - id: compress
            name: Compression
    if: ${{ contains(github.event.head_commit.message, '[benchmark]') || github.event.label.name == 'benchmark' && github.event_name == 'pull_request' }}
    steps:
      - uses: runs-on/action@v1
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha }}
          submodules: "recursive"
      # rustup is pre-installed on the ubuntu24-full-x64 image.

      # The compression benchmarks rely on DuckDB being installed to convert CSV to Parquet
      - name: Install DuckDB
        uses: opt-nc/setup-duckdb-action@v1.0.12
        with:
          version: v1.2.1

      - name: Build binary
        shell: bash
        env:
          RUSTFLAGS: '-C target-cpu=native -C force-frame-pointers=yes'
        run: |
          cargo build --bin ${{ matrix.benchmark.id }} --package bench-vortex --profile release_debug

      - name: Setup Polar Signals
        uses: polarsignals/gh-actions-ps-profiling@v0.3.0
        with:
          polarsignals_cloud_token: ${{ secrets.POLAR_SIGNALS_API_KEY }}
          labels: 'branch=${{ github.ref_name }};gh_run_id=${{ github.run_id }};benchmark=${{ matrix.benchmark.id }}'
          profiling_frequency: 200

      - name: Run ${{ matrix.benchmark.name }} benchmark
        shell: bash
        run: |
          target/release_debug/${{ matrix.benchmark.id }} -d gh-json | tee ${{ matrix.benchmark.id }}.json

      - name: Setup AWS CLI
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::375504701696:role/GitHubBenchmarkRole
          aws-region: us-east-1

      - name: Install uv
        uses: spiraldb/actions/.github/actions/setup-uv@0.8.0
        with:
          sync: false

      - name: Compare results
        shell: bash
        run: |
          set -Eeu -o pipefail -x

          base_commit_sha=${{ github.event.pull_request.base.sha }}

          aws s3 cp s3://vortex-benchmark-results-database/data.json - \
            | grep $base_commit_sha \
            > base.json

          echo '# Benchmarks: ${{ matrix.benchmark.id }}' > comment.md
          echo '<details>' >> comment.md
          echo '<summary>Table of Results</summary>' >> comment.md
          echo '' >> comment.md
          uv run --no-project scripts/compare-benchmark-jsons.py base.json ${{ matrix.benchmark.id }}.json \
            >> comment.md
          echo '</details>' >> comment.md

      - name: Comment PR
        uses: thollander/actions-comment-pull-request@v3
        with:
          file-path: comment.md
          comment-tag: bench-pr-comment-${{ matrix.benchmark.id }}

  sql:
    needs: label_trigger
    uses: ./.github/workflows/sql-benchmarks.yml
    secrets: inherit
    with:
      mode: 'pr'
