name: "SQL-related benchmarks"

on:
  workflow_call:
    inputs:
      mode:
        required: true
        type: string

jobs:
  bench:
    strategy:
      fail-fast: false
      matrix:
        # Regarding "include:":
        # https://docs.github.com/en/actions/writing-workflows/choosing-what-your-workflow-does/running-variations-of-jobs-in-a-workflow#example-adding-configurations
        include:
          - id: tpch-nvme
            binary_name: tpch
            name: TPC-H on NVME
            cloud_provider: gcp
          - id: clickbench-nvme
            binary_name: clickbench
            name: Clickbench on NVME
            cloud_provider: gcp
          - id: tpch-s3
            binary_name: tpch
            name: TPC-H on S3
            cloud_provider: aws
            remote_storage: s3://vortex-bench-dev/tpch-sf1/
    runs-on: [ self-hosted, ${{ matrix.cloud_provider }} ]
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/cleanup
      - uses: ./.github/actions/setup-rust
      - name: Set tempdir
        if: runner.environment == 'self-hosted'
        run: |
          echo "TMPDIR=/work" >> $GITHUB_ENV

      - name: Run ${{ matrix.name }} benchmark
        if: matrix.remote_storage == null
        shell: bash
        env:
          BENCH_VORTEX_RATIOS: '.*'
          RUSTFLAGS: '-C target-cpu=native'
        run: |
          cargo run \
              --bin ${{ matrix.binary_name }} \
              --release \
              -- \
              -d gh-json \
            | tee results.json

      - name: Run ${{ matrix.name }} benchmark
        if: matrix.remote_storage != null
        shell: bash
        env:
          BENCH_VORTEX_RATIOS: '.*'
          RUSTFLAGS: '-C target-cpu=native'
        run: |
          cargo run \
              --bin ${{ matrix.binary_name }} \
              --release \
              -- \
              --use-remote-data-dir ${{ matrix.remote_storage }} \
              --formats 'parquet,vortex' \
              -d gh-json \
            | tee results.json

      - name: Setup AWS CLI
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::375504701696:role/GitHubBenchmarkRole
          aws-region: us-east-1
      - name: Install uv
        if: inputs.mode == 'pr'
        uses: astral-sh/setup-uv@v5
      - name: Compare results
        if: inputs.mode == 'pr'
        shell: bash
        run: |
          set -Eeu -o pipefail -x

          base_commit_sha=${{ github.event.pull_request.base.sha }}

          aws s3 cp s3://vortex-benchmark-results-database/data.json - \
            | grep $base_commit_sha \
            > base.json

          echo '# Benchmarks: ${{ matrix.name }}' > comment.md
          echo '<details>' >> comment.md
          echo '<summary>Table of Results</summary>' >> comment.md
          echo '' >> comment.md
          uv run --no-project scripts/compare-benchmark-jsons.py base.json results.json \
            >> comment.md
          echo '</details>' >> comment.md
      - name: Comment PR
        if: inputs.mode == 'pr'
        uses: thollander/actions-comment-pull-request@v3
        with:
          file-path: comment.md
          # There is exactly one comment per comment-tag. If a comment with this tag already exists,
          # this action will *update* the comment instead of posting a new comment. Therefore, each
          # unique benchmark configuration must have a unique comment-tag.
          comment-tag: bench-pr-comment-{{ matrix.id }}
      - name: Upload Benchmark Results
        if: inputs.mode == 'develop'
        shell: bash
        run: |
          bash scripts/cat-s3.sh vortex-benchmark-results-database data.json results.json
