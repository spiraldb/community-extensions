name: "SQL-related benchmarks"

on:
  workflow_call:
    inputs:
      mode:
        required: true
        type: string

jobs:
  bench:
    # S3 is shared state here, and we want to make sure only one of each job runs at a time
    concurrency:
      group: ${{ github.workflow }}-${{ github.ref_name }}-${{matrix.id}}
      cancel-in-progress: false
    strategy:
      fail-fast: false
      matrix:
        # Regarding "include:":
        # https://docs.github.com/en/actions/writing-workflows/choosing-what-your-workflow-does/running-variations-of-jobs-in-a-workflow#example-adding-configurations
        include:
          - id: tpch-nvme
            binary_name: tpch
            name: TPC-H on NVME
            local_dir: bench-vortex/data/tpch/1
          - id: clickbench-nvme
            binary_name: clickbench
            name: Clickbench on NVME
            local_dir: bench-vortex/data/clickbench_partitioned
          - id: tpch-s3
            binary_name: tpch
            name: TPC-H on S3
            local_dir: bench-vortex/data/tpch/1
            remote_storage: s3://vortex-bench-dev-eu/${{github.ref_name}}/tpch-sf1/
    runs-on:
      - runs-on=${{ github.run_id }}
      - family=c6id.8xlarge
      - image=ubuntu24-full-x64
      - spot=false
      - tag=${{ matrix.id }}

    steps:
      - uses: runs-on/action@v1
      - uses: actions/checkout@v4
        if: inputs.mode == 'pr'
        with:
          ref: ${{ github.event.pull_request.head.sha }}
          submodules: "recursive"

      - uses: actions/checkout@v4
        if: inputs.mode != 'pr'
        with:
          submodules: "recursive"

      - name: Setup AWS CLI
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::375504701696:role/GitHubBenchmarkRole
          aws-region: us-east-1

      - name: Build binary
        shell: bash
        env:
          RUSTFLAGS: '-C target-cpu=native -C force-frame-pointers=yes'
        run: |
          cargo build --bin ${{ matrix.binary_name }} --package bench-vortex --profile release_debug

      - name: Generate data
        shell: bash
        run:
          # Generate data, running each query once to make sure they don't panic.
          target/release_debug/${{ matrix.binary_name }} --formats parquet,vortex -i1

      - name: Upload data
        if: matrix.remote_storage != null
        shell: bash
        env:
          AWS_REGION: 'eu-west-1'
        run: |
          aws s3 rm --recursive ${{ matrix.remote_storage }}
          aws s3 cp --recursive ${{matrix.local_dir}} ${{ matrix.remote_storage }}

      - name: Setup Polar Signals
        uses: polarsignals/gh-actions-ps-profiling@v0.2.0
        with:
          polarsignals_cloud_token: ${{ secrets.POLAR_SIGNALS_API_KEY }}
          labels: 'branch=${{ github.ref_name }};gh_run_id=${{ github.run_id }};benchmark=${{ matrix.id }}'
          profiling_frequency: 200

      - name: Run ${{ matrix.name }} benchmark
        if: matrix.remote_storage == null
        shell: bash
        env:
          OTEL_SERVICE_NAME: 'vortex-bench'
          OTEL_EXPORTER_OTLP_PROTOCOL: 'http/protobuf'
          OTEL_EXPORTER_OTLP_ENDPOINT: '${{ secrets.OTEL_EXPORTER_OTLP_ENDPOINT }}'
          OTEL_EXPORTER_OTLP_HEADERS: '${{ secrets.OTEL_EXPORTER_OTLP_HEADERS }}'
          OTEL_RESOURCE_ATTRIBUTES: 'bench-name=${{ matrix.id }}'
        run: |
          target/release_debug/${{ matrix.binary_name }} \
            -d gh-json \
            --export-spans \
          | tee results.json

      - name: Run ${{ matrix.name }} benchmark
        if: matrix.remote_storage != null
        shell: bash
        env:
          AWS_REGION: 'eu-west-1'
          OTEL_SERVICE_NAME: 'vortex-bench'
          OTEL_EXPORTER_OTLP_PROTOCOL: 'http/protobuf'
          OTEL_EXPORTER_OTLP_ENDPOINT: '${{ secrets.OTEL_EXPORTER_OTLP_ENDPOINT }}'
          OTEL_EXPORTER_OTLP_HEADERS: '${{ secrets.OTEL_EXPORTER_OTLP_HEADERS }}'
          OTEL_RESOURCE_ATTRIBUTES: 'bench-name=${{ matrix.id }}'
        run: |
          target/release_debug/${{ matrix.binary_name }} \
              --use-remote-data-dir ${{ matrix.remote_storage }} \
              --formats parquet,vortex \
              --export-spans \
              -d gh-json \
            | tee results.json

      - name: Install uv
        if: inputs.mode == 'pr'
        uses: spiraldb/actions/.github/actions/setup-uv@0.7.0
        with:
          sync: false
      - name: Compare results

        if: inputs.mode == 'pr'
        shell: bash
        run: |
          set -Eeu -o pipefail -x

          base_commit_sha=${{ github.event.pull_request.base.sha }}

          aws s3 cp s3://vortex-benchmark-results-database/data.json - \
            | grep $base_commit_sha \
            > base.json

          echo '# Benchmarks: ${{ matrix.name }}' > comment.md
          echo '<details>' >> comment.md
          echo '<summary>Table of Results</summary>' >> comment.md
          echo '' >> comment.md
          uv run --no-project scripts/compare-benchmark-jsons.py base.json results.json \
            >> comment.md
          echo '</details>' >> comment.md

      - name: Comment PR
        if: inputs.mode == 'pr'
        uses: thollander/actions-comment-pull-request@v3
        with:
          file-path: comment.md
          # There is exactly one comment per comment-tag. If a comment with this tag already exists,
          # this action will *update* the comment instead of posting a new comment. Therefore, each
          # unique benchmark configuration must have a unique comment-tag.
          comment-tag: bench-pr-comment-${{ matrix.id }}

      - name: Upload Benchmark Results
        if: inputs.mode == 'develop'
        shell: bash
        run: |
          bash scripts/cat-s3.sh vortex-benchmark-results-database data.json results.json
