name: "SQL-related benchmarks"

env:
  DUCKDB_VERSION: v1.2.2

on:
  workflow_call:
    inputs:
      mode:
        required: true
        type: string

jobs:
  build-duckdb:
    runs-on:
      - runs-on=${{ github.run_id }}
      - family=c6id.8xlarge
      - image=ubuntu24-full-x64
      - spot=false
      - tag=${{ matrix.id }}
    steps:
      - uses: runs-on/action@v1
      - name: Cache duckdb compiled binary
        uses: runs-on/cache@v4
        id: cache-duckdb-binary
        with:
          key: "${{ runner.os }}-duckdb-linux_amd64-${{ env.DUCKDB_VERSION }}"
          path: ${{ github.workspace }}/duckdb/build/release/duckdb

      - name: Install duckdb compile requirements
        if: steps.cache-duckdb-binary.outputs.cache-hit != 'true'
        run: sudo apt-get update && sudo apt-get install ninja-build cmake build-essential make ccache clang -y

      - name: Build duckdb binary
        if: steps.cache-duckdb-binary.outputs.cache-hit != 'true'
        env:
          CC: clang
          CXX: clang++
          GEN: ninja
          NATIVE_ARCH: 1
          DUCKDB_PLATFORM: linux_amd64
          LTO: thin
        run: |
          git clone https://github.com/duckdb/duckdb
          cd duckdb
          git checkout "$DUCKDB_VERSION"
          make release

  bench:
    needs: build-duckdb
    # S3 is shared state here, and we want to make sure only one of each job runs at a time
    concurrency:
      group: ${{ github.workflow }}-${{ github.ref_name }}-${{matrix.id}}
      cancel-in-progress: false
    strategy:
      fail-fast: false
      matrix:
        # Regarding "include:":
        # https://docs.github.com/en/actions/writing-workflows/choosing-what-your-workflow-does/running-variations-of-jobs-in-a-workflow#example-adding-configurations
        include:
          - id: tpch-nvme
            binary_name: tpch
            name: TPC-H on NVME
            local_dir: bench-vortex/data/tpch/1
            targets: "datafusion:arrow,datafusion:parquet,datafusion:vortex,duckdb:parquet,duckdb:vortex,duckdb:duckdb"
          - id: clickbench-nvme
            binary_name: clickbench
            name: Clickbench on NVME
            local_dir: bench-vortex/data/clickbench_partitioned
            targets: "datafusion:parquet,datafusion:vortex,duckdb:parquet,duckdb:vortex,duckdb:duckdb"
          - id: tpch-s3
            binary_name: tpch
            name: TPC-H on S3
            local_dir: bench-vortex/data/tpch/1
            remote_storage: s3://vortex-bench-dev-eu/${{github.ref_name}}/tpch/1/
            targets: "datafusion:parquet,datafusion:vortex,duckdb:parquet,duckdb:vortex"
    runs-on:
      - runs-on=${{ github.run_id }}
      - family=c6id.8xlarge
      - image=ubuntu24-full-x64
      - spot=false
      - tag=${{ matrix.id }}

    steps:
      - uses: runs-on/action@v1
      - uses: actions/checkout@v4
        if: inputs.mode == 'pr'
        with:
          ref: ${{ github.event.pull_request.head.sha }}
          submodules: "recursive"

      - uses: actions/checkout@v4
        if: inputs.mode != 'pr'
        with:
          submodules: "recursive"

      - name: Cache duckdb compiled binary
        uses: runs-on/cache@v4
        id: cache-duckdb-binary
        with:
          fail-on-cache-miss: true
          key: "${{ runner.os }}-duckdb-linux_amd64-${{ env.DUCKDB_VERSION }}"
          path: ${{ github.workspace }}/duckdb/build/release/duckdb

      - name: Add duckdb to path
        run: |
          echo "${{ github.workspace }}/duckdb/build/release/" >> $GITHUB_PATH

      - name: Verify duckdb available
        run: duckdb --version

      - name: Setup AWS CLI
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::375504701696:role/GitHubBenchmarkRole
          aws-region: us-east-1

      - name: Build binary
        shell: bash
        env:
          RUSTFLAGS: '-C target-cpu=native -C force-frame-pointers=yes'
        run: |
          cargo build --bin ${{ matrix.binary_name }} --package bench-vortex --profile release_debug

      - name: Install ninja & gzip
        run: sudo apt-get update && sudo apt-get install -y ninja-build gzip

      - name: DuckDB extension build
        env:
          # Build DuckDB and the Vortex extension with `-march=native`.
          # The `NATIVE_ARCH` environment variable is picked up by `duckdb/Makefile`.
          NATIVE_ARCH: 1
          DUCKDB_PLATFORM: linux_amd64
          CFLAGS: -ftls-model=global-dynamic
        run: GEN=ninja make release
        working-directory: ${{ github.workspace }}/duckdb-vortex

      - name: Generate data
        shell: bash
        env:
          RUST_BACKTRACE: 1
        run: |
          # Generate data, running each query once to make sure they don't panic.
          target/release_debug/${{ matrix.binary_name }} --targets datafusion:parquet -i1 -d gh-json --skip-duckdb-build
          target/release_debug/${{ matrix.binary_name }} --targets datafusion:vortex -i1 -d gh-json --skip-duckdb-build
          target/release_debug/${{ matrix.binary_name }} --targets duckdb:vortex -i1 -d gh-json --skip-duckdb-build

      - name: Upload data
        if: matrix.remote_storage != null
        shell: bash
        env:
          AWS_REGION: 'eu-west-1'
        run: |
          aws s3 rm --recursive ${{ matrix.remote_storage }}
          aws s3 cp --recursive ${{matrix.local_dir}} ${{ matrix.remote_storage }}

      - name: Setup Polar Signals
        uses: polarsignals/gh-actions-ps-profiling@v0.4.0
        with:
          polarsignals_cloud_token: ${{ secrets.POLAR_SIGNALS_API_KEY }}
          labels: 'branch=${{ github.ref_name }};gh_run_id=${{ github.run_id }};benchmark=${{ matrix.id }}'
          profiling_frequency: 200

      - name: Run ${{ matrix.name }} benchmark
        if: matrix.remote_storage == null
        shell: bash
        env:
          OTEL_SERVICE_NAME: 'vortex-bench'
          OTEL_EXPORTER_OTLP_PROTOCOL: 'http/protobuf'
          OTEL_EXPORTER_OTLP_ENDPOINT: '${{ secrets.OTEL_EXPORTER_OTLP_ENDPOINT }}'
          OTEL_EXPORTER_OTLP_HEADERS: '${{ secrets.OTEL_EXPORTER_OTLP_HEADERS }}'
          OTEL_RESOURCE_ATTRIBUTES: 'bench-name=${{ matrix.id }}'
        run: |
          target/release_debug/${{ matrix.binary_name }} \
            -d gh-json \
            --targets ${{ matrix.targets }} \
            --export-spans \
            --skip-duckdb-build \
          | tee results.json

      - name: Run ${{ matrix.name }} benchmark (remote)
        if: matrix.remote_storage != null
        shell: bash
        env:
          AWS_REGION: 'eu-west-1'
          OTEL_SERVICE_NAME: 'vortex-bench'
          OTEL_EXPORTER_OTLP_PROTOCOL: 'http/protobuf'
          OTEL_EXPORTER_OTLP_ENDPOINT: '${{ secrets.OTEL_EXPORTER_OTLP_ENDPOINT }}'
          OTEL_EXPORTER_OTLP_HEADERS: '${{ secrets.OTEL_EXPORTER_OTLP_HEADERS }}'
          OTEL_RESOURCE_ATTRIBUTES: 'bench-name=${{ matrix.id }}'
        run: |
          target/release_debug/${{ matrix.binary_name }} \
              --use-remote-data-dir ${{ matrix.remote_storage }} \
              --targets ${{ matrix.targets }} \
              --export-spans \
              --skip-duckdb-build \
              -d gh-json \
            | tee results.json

      - name: Install uv
        if: inputs.mode == 'pr'
        uses: spiraldb/actions/.github/actions/setup-uv@0.11.0
        with:
          sync: false
      - name: Compare results

        if: inputs.mode == 'pr'
        shell: bash
        run: |
          set -Eeu -o pipefail -x

          base_commit_sha=${{ github.event.pull_request.base.sha }}

          aws s3 cp s3://vortex-benchmark-results-database/data.json.gz - \
            | gzip -d \
            | grep $base_commit_sha \
            > base.json

          echo '# Benchmarks: ${{ matrix.name }}' > comment.md
          echo '<details>' >> comment.md
          echo '<summary>Table of Results</summary>' >> comment.md
          echo '' >> comment.md
          uv run --no-project scripts/compare-benchmark-jsons.py base.json results.json \
            >> comment.md
          echo '</details>' >> comment.md

      - name: Comment PR
        if: inputs.mode == 'pr'
        uses: thollander/actions-comment-pull-request@v3
        with:
          file-path: comment.md
          # There is exactly one comment per comment-tag. If a comment with this tag already exists,
          # this action will *update* the comment instead of posting a new comment. Therefore, each
          # unique benchmark configuration must have a unique comment-tag.
          comment-tag: bench-pr-comment-${{ matrix.id }}

      - name: Upload Benchmark Results
        if: inputs.mode == 'develop'
        shell: bash
        run: |
          bash scripts/cat-s3.sh vortex-benchmark-results-database data.json.gz results.json
